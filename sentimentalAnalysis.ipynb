{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e2b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_sentiment_analysis.py\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "# ===== STEP 1: Data Loading =====\n",
    "print(\"\\n=== STEP 1: Loading Data ===\")\n",
    "import os\n",
    "file_path = 'IMDB_Dataset.csv'\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"Error: File not found at {os.path.abspath(file_path)}\")\n",
    "    print(\"Please ensure the CSV file is in the same directory as your script\")\n",
    "    exit()\n",
    "df = pd.read_csv('IMDB_Dataset.csv')\n",
    "# Synthetic mini dataset (20 samples)\n",
    "# data = {\n",
    "#     'review': [\n",
    "#         \"This movie was fantastic! The acting was superb.\",\n",
    "#         \"Terrible plot and bad acting throughout.\",\n",
    "#         \"I loved every minute of this film.\",\n",
    "#         \"Worst movie I've ever seen.\",\n",
    "#         \"The cinematography was beautiful.\",\n",
    "#         \"Boring and predictable storyline.\",\n",
    "#         \"A masterpiece of modern cinema.\",\n",
    "#         \"Complete waste of time.\",\n",
    "#         \"The performances were outstanding.\",\n",
    "#         \"I couldn't stand this film.\",\n",
    "#         \"Highly recommended for all audiences.\",\n",
    "#         \"Painfully bad dialogue.\",\n",
    "#         \"The director did an amazing job.\",\n",
    "#         \"I fell asleep halfway through.\",\n",
    "#         \"Perfect from start to finish.\",\n",
    "#         \"Unbearably long and dull.\",\n",
    "#         \"The soundtrack was incredible.\",\n",
    "#         \"Not a single redeeming quality.\",\n",
    "#         \"One of the best films this year.\",\n",
    "#         \"I want my money back.\"\n",
    "#     ],\n",
    "#     'sentiment': [\n",
    "#         \"positive\", \"negative\", \"positive\", \"negative\", \"positive\",\n",
    "#         \"negative\", \"positive\", \"negative\", \"positive\", \"negative\",\n",
    "#         \"positive\", \"negative\", \"positive\", \"negative\", \"positive\",\n",
    "#         \"negative\", \"positive\", \"negative\", \"positive\", \"negative\"\n",
    "#     ]\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['review'].values,\n",
    "    df['sentiment'].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25256ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nData loaded:\")\n",
    "print(f\"- Training samples: {len(train_texts)}\")\n",
    "print(f\"- Validation samples: {len(val_texts)}\")\n",
    "print(f\"- Sample review: {train_texts[0][:50]}...\")\n",
    "print(f\"- Corresponding label: {'Positive' if train_labels[0] == 1 else 'Negative'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf60494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP 2: Tokenization =====\n",
    "print(\"\\n=== STEP 2: Tokenizing Text ===\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52acc08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize a sample first to see output\n",
    "sample_text = \"This movie was great!\"\n",
    "sample_tokens = tokenizer(sample_text, truncation=True, padding='max_length', max_length=16)\n",
    "print(f\"\\nSample tokenization for: '{sample_text}'\")\n",
    "print(f\"- Input IDs: {sample_tokens['input_ids']}\")\n",
    "print(f\"- Attention Mask: {sample_tokens['attention_mask']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c6054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all data\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a3e5d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ===== STEP 3: Dataset Preparation =====\n",
    "print(\"\\n=== STEP 3: Creating PyTorch Dataset ===\")\n",
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f698236",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IMDbDataset(train_encodings, train_labels)\n",
    "val_dataset = IMDbDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1004e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDataset created:\")\n",
    "print(f\"- First training sample keys: {list(train_dataset[0].keys())}\")\n",
    "print(f\"- Input IDs shape: {train_dataset[0]['input_ids'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP 4: Model Initialization =====\n",
    "print(\"\\n=== STEP 4: Loading BERT Model ===\")\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b698c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a single sample\n",
    "sample = train_dataset[0]\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=sample['input_ids'].unsqueeze(0),\n",
    "                   attention_mask=sample['attention_mask'].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944cedc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nModel initialized:\")\n",
    "print(f\"- Sample output logits: {outputs.logits}\")\n",
    "print(f\"- Predicted class: {'Positive' if outputs.logits.argmax().item() == 1 else 'Negative'}\")\n",
    "print(f\"- Actual class: {'Positive' if sample['labels'].item() == 1 else 'Negative'}\")\n",
    "#\n",
    "# ===== STEP 5: Configuring Training =====\n",
    "print(\"\\n=== STEP 5: Configuring Training ===\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,  # Start with 1 epoch for testing\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",\n",
    "    save_strategy=\"no\",\n",
    "    use_cpu=not torch.cuda.is_available()  # Updated parameter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320faaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=lambda p: {'accuracy': accuracy_score(p.label_ids, p.predictions.argmax(axis=1))}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eac2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP 6: Execute Training =====\n",
    "print(\"\\n=== STEP 6: Starting Training ===\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87960948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STEP 7: Quick Prediction Test =====\n",
    "print(\"\\n=== STEP 7: Making Predictions ===\")\n",
    "test_reviews = [\n",
    "    \"This film was absolutely wonderful!\",\n",
    "    \"Terrible acting and boring plot.\",\n",
    "    \"The movie was okay, not great but not bad either.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5eb096",
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in test_reviews:\n",
    "    inputs = tokenizer(review, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    prediction = outputs.logits.argmax().item()\n",
    "    print(f\"\\nReview: {review}\")\n",
    "    print(f\"Predicted sentiment: {'Positive' if prediction == 1 else 'Negative'}\")\n",
    "    print(f\"Confidence scores: {torch.softmax(outputs.logits, dim=1).tolist()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0af00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Enhanced Evaluation =====\n",
    "print(\"\\n=== Enhanced Evaluation ===\")\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6461ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all predictions\n",
    "predictions = trainer.predict(val_dataset)\n",
    "preds = predictions.predictions.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dbd373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(val_labels, preds, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0450fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(val_labels, preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negative', 'Positive'])\n",
    "disp.plot()\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42df77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Model Saving =====\n",
    "print(\"\\n=== Saving Model ===\")\n",
    "model.save_pretrained(\"./sentiment_model\")\n",
    "tokenizer.save_pretrained(\"./sentiment_model\")\n",
    "print(\"Model and tokenizer saved to 'sentiment_model' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24027fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Model Loading =====\n",
    "print(\"\\n=== Loading Model ===\")\n",
    "loaded_model = BertForSequenceClassification.from_pretrained(\"./sentiment_model\")\n",
    "loaded_tokenizer = BertTokenizer.from_pretrained(\"./sentiment_model\")\n",
    "print(\"Model successfully loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c1941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Interactive Prediction =====\n",
    "def predict_interactive():\n",
    "    while True:\n",
    "        text = input(\"\\nEnter a review (or 'quit' to exit): \")\n",
    "        if text.lower() == 'quit':\n",
    "            break\n",
    "\n",
    "        inputs = loaded_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "        with torch.no_grad():\n",
    "            outputs = loaded_model(**inputs)\n",
    "\n",
    "        probs = torch.softmax(outputs.logits, dim=1)[0]\n",
    "        pred = outputs.logits.argmax().item()\n",
    "\n",
    "        print(f\"\\nPredicted: {'Positive' if pred == 1 else 'Negative'}\")\n",
    "        print(f\"Confidence: {probs[pred]:.2%}\")\n",
    "        print(f\"Negative: {probs[0]:.2%} | Positive: {probs[1]:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e962e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Interactive Mode ===\")\n",
    "predict_interactive()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
